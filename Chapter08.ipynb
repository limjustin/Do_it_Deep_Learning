{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZtpmNMmRS7tq4StX2hBvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/limjustin/Do_it_Deep_Learning/blob/master/Chapter08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8wTgO8jSH2-",
        "colab_type": "text"
      },
      "source": [
        "## 08-1. 합성곱 연산에 대해 알아보기\n",
        "\n",
        "#### 합성곱(convolution) 연산\n",
        "**개념**\n",
        "- 원본 배열 x와 미끄러지는 배열 w가 존재\n",
        "- w 배열의 원소 순서를 뒤집음(reverse)\n",
        "- x와 w의 각 배열 원소끼리 곱한 후 더하는 연산을 수행 (점 곱 연산)\n",
        "- w를 오른쪽으로 한 칸 이동시켜서 같은 연산 수행\n",
        "\n",
        "**구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYHCCt9WWDBz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "627df176-c4ee-4184-97f2-905cd9d0cd35"
      },
      "source": [
        "## 1. 넘파이 배열 정의하고 배열 하나 선택해 뒤집기\n",
        "\n",
        "import numpy as np\n",
        "w = np.array([2, 1, 5, 3])\n",
        "x = np.array([2, 8, 3, 7, 1, 2, 0, 4, 5])\n",
        "\n",
        "w_r = np.flip(w)    # flip() 함수를 사용해 배열에 대한 reverse 연산 수행\n",
        "print(w_r)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 5 1 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0qNPQHRWp1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "20f16bbb-ac26-4ff9-8753-616933ac8370"
      },
      "source": [
        "## 2. 넘파이의 점 곱으로 합성곱 연산 수행하기\n",
        "\n",
        "for i in range(6):\n",
        "  print(np.dot(x[i:i+4], w_r))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63\n",
            "48\n",
            "49\n",
            "28\n",
            "21\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7qpRyTFW4mz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf52f00b-9962-4947-eb03-fc80a4139167"
      },
      "source": [
        "## 3. 싸이파이로 합성곱 수행하기\n",
        "\n",
        "from scipy.signal import convolve\n",
        "convolve(x, w, mode='valid')    # scipy에서 합성곱 연산을 위한 함수 convolve()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([63, 48, 49, 28, 21, 20])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGwxoG5nXFKU",
        "colab_type": "text"
      },
      "source": [
        "#### 교차 상관(cross-correlation) 연산\n",
        "**개념**\n",
        "- 사실 합성곱 신경망은 교차 상관을 사용\n",
        "- 합성곱과 동일한 방법으로 연산을 진행\n",
        "- 하지만 **'미끄러지는 배열을 뒤집지 않는다'**는 점이 다름\n",
        "\n",
        "**구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO8lnVojXsez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c241d2d3-c9d0-4c48-e01a-3e10ff600523"
      },
      "source": [
        "from scipy.signal import correlate\n",
        "correlate(x, w, mode='valid')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([48, 57, 24, 25, 16, 39])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkBSQc0QX2GN",
        "colab_type": "text"
      },
      "source": [
        "**합성곱 신경망에서 교차 상관을 사용하는 이유**\n",
        "```\n",
        "모델 훈련 과정\n",
        "1. 가중치를 무작위 값으로 초기화\n",
        "2. 모든 샘플에 대하여 정방향과 역방향 계산을 수행하여 가중치를 조금씩 학습(업데이트)\n",
        "```\n",
        "- 모든 모델은 훈련하기 전에 가중치 배열의 요소들을 무작위로 초기화함\n",
        "- 여기서 가중치 배열은 '미끄러지는 배열'\n",
        "- 가중치 배열은 무작위로 이미 초기화되어 있기 때문에 **가중치를 뒤집어서 적용하던지 여부는 상관이 없음**\n",
        "- 그래서 그냥 **가중치 배열을 뒤집지 않는 교차 상관**을 사용한다!!\n",
        "\n",
        "#### 패딩(padding)\n",
        "**개념**\n",
        "- **원본 배열**의 양 끝에 빈 원소를 추가하는 것\n",
        "\n",
        "**종류**\n",
        "- 밸리드 패딩(valid padding)\n",
        "  - 밸리드 패딩의 결과로 얻는 배열의 크기는 항상 원본 배열의 크기보다 작음\n",
        "  - 원본 배열의 각 원소가 **연산에 참여하는 정도가 다른 것**이 특징\n",
        "  -```correlate(x, w, mode='valid')```\n",
        "- 풀 패딩(full padding)\n",
        "  - **원본 배열의 양 끝에 가상의 원소를 추가**하는 '제로 패딩(zero padding)' 과정이 필요\n",
        "  - 적절한 개수의 제로 패딩을 추가하면 **원본 배열의 모든 원소가 연산에 동일하게 참여**할 수 있음\n",
        "  - **원본 배열의 모든 요소가 동일하게 연산에 참여**하는 것이 특징\n",
        "  -```correlate(x, w, mode='full')```  \n",
        "- 세임 패딩(same padding)\n",
        "  - **출력 배열의 길이가 원본 배열의 길이와 같아지도록** 원본 배열에 제로 패딩을 추가\n",
        "  - ```correlate(x, w, mode='same')```\n",
        "\n",
        "#### 스트라이드(stride)\n",
        "**개념**\n",
        "- 미끄러지는 배열의 간격을 조절하는 것\n",
        "- 합성곱 신경망을 만들 때는 보통 스트라이드를 1로 지정\n",
        "\n",
        "#### 2차원 배열에서 합성곱 수행하기\n",
        "- 합성곱의 수행 방향 : 왼쪽 -> 오른쪽, 위 -> 아래"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZuCj4CAbcy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "15ac7c72-7333-4cc8-ec79-8ea50a4101ad"
      },
      "source": [
        "x = np.array([[1, 2, 3],\n",
        "              [4, 5, 6],\n",
        "              [7, 8, 9]])\n",
        "w = np.array([[2, 0], [0, 0]])\n",
        "from scipy.signal import correlate2d    # correlate2d() 함수를 사용하여 2차원 배열의 합성곱 계산\n",
        "correlate2d(x, w, mode='valid')\n",
        "correlate2d(x, w, mode='same')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2,  4,  6],\n",
              "       [ 8, 10, 12],\n",
              "       [14, 16, 18]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e73thbKbd8kM",
        "colab_type": "text"
      },
      "source": [
        "#### 텐서플로로 합성곱 수행하기\n",
        "**원리**\n",
        "- scipy 말고 tensorflow에서도 합성곱을 위한 함수 제공\n",
        "- 원본 배열 : 입력 / 미끄러지는 배열 : 가중치\n",
        "\n",
        "**합성곱 신경망의 입력은 일반적으로 4차원 배열**\n",
        "- 입력으로 4차원 배열을 기대함\n",
        "- 이유 : 입력 이미지의 **높이와 너비 외에 더 많은 차원이 필요**하기 때문\n",
        "- 입력 배열의 구성\n",
        "  - (배치, 샘플의 높이, 샘플의 너비, 컬러 채널의 차원)\n",
        "- 가중치 배열의 구성\n",
        "  - (가중치의 높이, 가중치의 너비, 채널, 가중치의 개수)\n",
        "- 합성곱 배열의 구성\n",
        "  - (입력의 배치, 입력의 높이, 입력의 너비, 필터의 개수)\n",
        "\n",
        "**2차원 배열을 4차원 배열로 바꿔 합성곱 수행**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptpgLKwcfRni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "43494b22-8e62-4ae0-b861-81e8c3147205"
      },
      "source": [
        "import tensorflow as tf\n",
        "x_4d = x.astype(np.float).reshape(1, 3, 3, 1)   # reshape() 메서드로 2차원 배열에서 4차원 배열로 바꾸기\n",
        "w_4d = w.reshape(2, 2, 1, 1)                    # astype() 메서드로 자료형을 실수로 바꾸기\n",
        "\n",
        "c_out = tf.nn.conv2d(x_4d, w_4d, strides=1, padding='SAME')   # 텐서플로에서 2차원 합성곱을 수행하는 함수는 conv2d() / 매개변수는 4차원 배열!!\n",
        "\n",
        "c_out.numpy().reshape(3, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.,  4.,  6.],\n",
              "       [ 8., 10., 12.],\n",
              "       [14., 16., 18.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKj420fkgfv3",
        "colab_type": "text"
      },
      "source": [
        "#### 합성곱 신경망이 이미지 분류에 더 뛰어난 성능을 보이는 이유\n",
        "- 가중치 배열의 크기가 작아짐(훨씬 가중치가 적음)\n",
        "- 간단한 용어 정리\n",
        "  - 필터(filter) : 합성곱의 가중치\n",
        "  - 커널(kernel) : 케라스에서 합성곱의 **필터 1개**\n",
        "  - '가중치'는 **필터 전체**를 지칭할 때 사용함\n",
        "\n",
        "\n",
        "## 08-2. 풀링 연산에 대해 알아보기\n",
        "**개념**\n",
        "- 합성곱층 : 합성곱이 일어나는 층\n",
        "- 풀링층 : 풀링이 일어나는 층\n",
        "- 특성 맵(feature map) : 합성곱층과 풀링층에서 만들어진 결과\n",
        "- 합성곱 신경망의 모습 : 합성곱층 뒤에 풀링층이 뒤따르는 형태\n",
        "- 풀링 : 특성 맵을 스캔하며 최댓값을 고르거나 평균값을 계산하는 것\n",
        "\n",
        "#### 최대 풀링(max pooling)\n",
        "**개념**\n",
        "- 특성 맵 위를 스캔하며 최댓값을 고르는 방식\n",
        "- 풀링 영역의 크기는 보통 2*2를 지정\n",
        "- 스트라이드는 풀링의 한 모서리 크기로 지정 (풀링 영역이 겹쳐지지 않도록 스캔)\n",
        "\n",
        "**효과**\n",
        "- 2*2 풀링은 특성 맵의 크기를 절반으로 줄임\n",
        "- 특성 맵의 한 요소가 입력의 더 넓은 영역을 바라볼 수 있는 효과 有\n",
        "- 최대 풀링의 요소들은 2*2 크기의 각 영역을 대표함\n",
        "\n",
        "#### 평균 풀링(average pooling)\n",
        "**개념**\n",
        "- 풀링 영역의 평균값을 계산\n",
        "\n",
        "#### 최대 풀링을 더 선호하는 이유\n",
        "- 평균 풀링은 **합성곱층을 통과하는 특징들을 희석**시킬 가능성이 높음\n",
        "- 입력에서 합성곱 필터가 찾고자 하는 부분은 **특성 맵의 가장 큰 값으로 활성화**\n",
        "- 평균 풀링은 **가장 큰 특성의 값을 상쇄** <-> 최대 풀링은 **가장 큰 특징을 유지**\n",
        "- 따라서, 최대 풀링이 **이미지 분류 작업에 더 적합**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yviQU-9BpwAN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fdae1e38-1659-4ebb-9df5-71f61f83212b"
      },
      "source": [
        "x = np.array([[1, 2, 3, 4],\n",
        "              [5, 6, 7, 8],\n",
        "              [9, 10, 11, 12],\n",
        "              [13, 14, 15, 16]])\n",
        "x = x.reshape(1, 4, 4, 1)\n",
        "\n",
        "p_out = tf.nn.max_pool2d(x, ksize=2, strides=2, padding='VALID')\n",
        "p_out.numpy().reshape(2, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6.,  8.],\n",
              "       [14., 16.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rsn4uDrXqiLH",
        "colab_type": "text"
      },
      "source": [
        "**풀링에 대해 필요한 사항**\n",
        "- 풀링층에는 학습되는 가중치가 없음\n",
        "- 풀링층을 통과하기 전후로 배치 크기와 채널 크기는 동일함\n",
        "\n",
        "## 08-3. 합성곱 신경망의 구조 알아보기\n",
        "\n",
        "#### 렐루(ReLU) 함수\n",
        "**개념**\n",
        "- 합성곱 신경망에서 자주 사용하는 활성화 함수\n",
        "- 합성곱층에 적용되는 활성화 함수\n",
        "- 합성곱 신경망의 성능을 더 높여줌\n",
        "- x가 0보다 작으면 y=0, 0보다 크면 y=x\n",
        "- 도함수는 x가 0보다 작으면 0, 0보다 크면 1\n",
        "\n",
        "**구현**\n",
        "```\n",
        "def relu(x):\n",
        "    return np.maximun(x, 0)\n",
        "```\n",
        "```\n",
        "r_out = tf.nn.relu(x)  # tensorflow에서 제공하는 렐루 함수는 relu()\n",
        "r_out.numpy()  # 화면에 출력하려면 Tensor 객체를 numpy로 변환해야 함\n",
        "```\n",
        "\n",
        "#### 합성곱 신경망에서 일어나는 일들과 구조\n",
        "**1. 합성곱층에서 일어나는 일**\n",
        "- 입력 데이터(이미지)에는 채널(channel)이라는 **차원을 하나 더 가짐**\n",
        "- 핵심1 : 이미지의 **모든 채널에 합성곱이 한 번에 적용**되어야 함\n",
        "  - 커널의 **마지막 차원**은 **입력 채널의 개수와 동일**해야 함\n",
        "  - ex) 입력 채널이 4x4x10의 형태라면, 커널 배열의 크기도 3x3**x10**으로 마지막 차원의 개수를 동일하게 맞춰주어야 함\n",
        "- 핵심2 : 입력 채널은 커널의 채널과 **각각 합성곱을 수행**, 그 후 합성곱의 전체 결과를 더하여 **특성 맵 1조각을 만듦**\n",
        "  - **커널이 하나**면 이미지의 **특징을 하나만 감지**\n",
        "  - **복수 개의 커널의 경우**에는 이미지에서 **여러 개의 특징을 감지**할 수 있음\n",
        "- **정리 : 합성곱층에 주입된 이미지는 특성을 감지하는 커널에 의해 특성 맵으로 만들어짐**\n",
        "\n",
        "**2. 풀링층에서 일어나는 일**\n",
        "- 합성곱층을 통해 특성 맵이 만들어짐\n",
        "- 핵심1 : 활성화 함수로 **렐루 함수가 적용**됨\n",
        "- 핵심2 : **풀링** 적용\n",
        "  - 풀링은 **특성 맵의 크기를 줄여줌**\n",
        "  - BUT 채널의 크기는 줄어들지 않음\n",
        "- **정리 : 합성곱층을 통해 만들어진 특성 맵은 활성화 함수(렐루)와 풀링층을 거쳐 더 작은 특성 맵이 됨 (채널의 개수는 유지)**\n",
        "\n",
        "**3. 완전 연결층에서 일어나는 일**\n",
        "- **합성곱층과 풀링층을 통과시켜 얻은 특성 맵**\n",
        "- 1. 이는 **일렬**로 펼쳐 **완전 연결층에 입력으로 주입**\n",
        "- 2. 출력층과 다중 분류를 위한 소프트맥스 함수를 통과하여 **최종 출력**을 만듦\n",
        "- 완전 연결층의 출력은 **출력층의 뉴런**과 연결\n",
        "- **정리 : 풀링층을 통해 만들어진 특성 맵을 일렬로 펼쳐 완전 연결층에 주입. 그 다음 출력층을 통과하여 최종 예측을 만듦**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnJ4_1IDUdUP",
        "colab_type": "text"
      },
      "source": [
        "## 08-4. 합성곱 신경망을 만들고 훈련하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lTN2PfLYBwf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvolutionNetwork:\n",
        "\n",
        "  def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
        "    self.n_kernels = n_kernels    # 합성곱의 커널 개수\n",
        "    self.kernel_size = 3    # 커널 크기\n",
        "    self.optimizer = None   # 옵티마이저\n",
        "    self.conv_w = None    # 합성곱층의 가중치\n",
        "    self.conv_b = None    # 합성곱층의 절편\n",
        "    self.units = units    # 은닉층의 뉴런 개수\n",
        "    self.batch_size = batch_size    # 배치 크기\n",
        "    self.w1 = None    # 은닉층의 가중치\n",
        "    self.b1 = None    # 은닉층의 절편\n",
        "    self.w2 = None    # 출력층의 가중치\n",
        "    self.b2 = None    # 출력층의 절편\n",
        "    self.a1 = None    # 은닉층의 활성화 출력\n",
        "    self.losses = []    # 훈련 손실\n",
        "    self.val_losses = []    # 검증 손실\n",
        "    self.lr = learning_rate   # 학습률\n",
        "\n",
        "  def forpass(self, x):\n",
        "    # 3x3 합성곱 연산을 수행합니다.\n",
        "    c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
        "    # 렐루 활성화 함수를 적용합니다.\n",
        "    r_out = tf.nn.relu(c_out)\n",
        "    # 2x2 최대 풀링을 적용합니다.\n",
        "    p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
        "    # 첫 번째 배치 차원을 제외하고 출력을 일렬로 펼칩니다.\n",
        "    f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
        "    z1 = tf.matmul(f_out, self.w1) + self.b1   # 첫 번째 층의 선형식 계산\n",
        "    a1 = tf.nn.relu(z1)    # 활성화 함수 적용\n",
        "    z2 = tf.matmul(a1, self.w2) + self.b2   # 두 번째 층의 선형식 계산\n",
        "    return z2\n",
        "\n",
        "  def init_weights(self, input_shape, n_classes):\n",
        "    g = tf.initializers.glorot_uniform()\n",
        "    self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
        "    self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
        "    n_features = 14 * 14 * self.n_kernels\n",
        "    self.w1 = tf.Variable(g((n_features, self.units)))    # (특성 개수, 은닉층의 크기)\n",
        "    self.b1 = tf.Variable(np.zeros(self.units), dtype=float)    # 은닉층의 크기\n",
        "    self.w2 = tf.Variable(g((self.units, n_classes)))   # (은닉층의 크기, 클래스 개수)\n",
        "    self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)   # 클래스 개수\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "    self.init_weights(x.shape, y.shape[1])   # 은닉층과 출력층의 가중치 초기화\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
        "    # epochs 만큼 반복\n",
        "    for i in range(epochs):\n",
        "      print('에포크', i, end=' ')\n",
        "      # 제너레이터 함수에서 반환한 미니 배치를 순환\n",
        "      batch_losses = []\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):\n",
        "          print('.', end='')\n",
        "          self.training(x_batch, y_batch)\n",
        "          # 배치 손실을 기록\n",
        "          batch_losses.append(self.get_loss(x_batch, y_batch))\n",
        "      print( )\n",
        "      # 배치 손실 평균을 내어 훈련 손실값으로 저장\n",
        "      self.losses.append(np.mean(batch_losses))\n",
        "      # 검증 세트에 대한 손실 계산\n",
        "      self.val_losses.append(self.get_loss(x_val, y_val))\n",
        "\n",
        "  # 미니 배치 제너레이터 함수\n",
        "  def gen_batch(self, x, y):\n",
        "    bins = len(x) // self.batch_size   # 미니 배치 횟수\n",
        "    indexes = np.random.permutation(np.arange(len(x)))    # 인덱스 섞기\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "    for i in range(bins):\n",
        "      start = self.batch_size * i\n",
        "      end = self.batch_size * (i + 1)\n",
        "      yield x[start:end], y[start:end]    # batch_size만큼 슬라이싱하여 반환\n",
        "\n",
        "  def training(self, x, y):\n",
        "    m = len(x)    # 샘플 개수 저장\n",
        "    with tf.GradientTape( ) as tape:\n",
        "      z = self.forpass(x)   # 정방향 계산을 수행\n",
        "      # 손실을 계산\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "    \n",
        "    weights_list = [self.conv_w, self.conv_b,\n",
        "                    self.w1, self.b1, self.w2, self.b2]\n",
        "    # 가중치에 대한 그레이디언트 계산\n",
        "    grads = tape.gradient(loss, weights_list)\n",
        "    # 가중치를 업데이트 함\n",
        "    self.optimizer.apply_gradients(zip(grads, weights_list))\n",
        "\n",
        "  def predict(self, x):\n",
        "    z = self.forpass(x)   # 정방향 계산 수행\n",
        "    return np.argmax(z.numpy(), axis=1)   # 가장 큰 값의 인덱스 반환\n",
        "\n",
        "  def score(self, x, y):\n",
        "    # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환\n",
        "    return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
        "\n",
        "  def get_loss(self, x, y):\n",
        "    z = self.forpass(x)   # 정방향 계산 수행\n",
        "    # 손실을 계산하여 저장\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
        "    return loss.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elvZoyzVfLzf",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### 합성곱 신경망 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU3DUIcRfP4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 1. 데이터 세트 불러오기\n",
        "\n",
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmfVBSoHfhsU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 2. 훈련 데이터 세트를 훈련 세트와 검증 세트로 나누기\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all,\n",
        "                                                  stratify=y_train_all, test_size=0.2,\n",
        "                                                  random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPx9AD2Xf64U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 3. 타깃을 원-핫 인코딩으로 변환하기\n",
        "\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vc34IfwPgUPe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "60a03d93-5751-46bd-9175-1a0bba988e70"
      },
      "source": [
        "## 4. 입력 데이터 준비하기\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)      # 마지막에 명암을 나타내는 1차원 채널을 추가\n",
        "x_val = x_val.reshape(-1, 28, 28, 1)\n",
        "\n",
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHc-yiPMgr2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 5. 입력 데이터 표준화 전처리하기\n",
        "\n",
        "x_train = x_train / 255   # 0~255 사이의 정수로 픽셀 강도를 표현하기 위해\n",
        "x_val = x_val / 255   # 255로 나누어 0~1 사이의 값으로 조정"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DecCfRD-hAEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "outputId": "86180b83-99d6-4665-d2ce-27421a70134c"
      },
      "source": [
        "## 6. 모델 훈련하기\n",
        "\n",
        "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\n",
        "cn.fit(x_train, y_train_encoded, x_val=x_val, y_val=y_val_encoded, epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 0 ............................................................................................"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-fa2162de28d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvolutionNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_kernels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-64-58fe9c07d5c3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, epochs, x_val, y_val)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m           \u001b[0;31m# 배치 손실을 기록\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0mbatch_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-58fe9c07d5c3>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# 샘플 개수 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 정방향 계산을 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m       \u001b[0;31m# 손실을 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-58fe9c07d5c3>\u001b[0m in \u001b[0;36mforpass\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# 3x3 합성곱 연산을 수행합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mc_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'SAME'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 렐루 활성화 함수를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mr_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2164\u001b[0m                 \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m                 \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2166\u001b[0;31m                 name=name)\n\u001b[0m\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2273\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2274\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2275\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2276\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    933\u001b[0m         \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m    936\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}